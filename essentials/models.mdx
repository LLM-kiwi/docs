---
title: "Available Models"
description: "AI models available on llm.kiwi by tier"
---

llm.kiwi provides access to a curated selection of high-performance AI models. Model availability depends on your subscription tier.

## Free Tier

The Free tier includes access to a single routing model:

<CardGroup cols={1}>
  <Card title="default" icon="gears">
    Intelligent model router that selects the best model for your request automatically.
  </Card>
</CardGroup>

| Model ID | Description |
| :--- | :--- |
| `default` | Auto-routing model — balances quality and speed for each request |

<Note>
  Free tier users **must** use `model="default"`. This model intelligently routes your requests to appropriate underlying models.
</Note>

---

## Pro Tier Models

Pro tier unlocks direct access to specific high-performance models:

### Chat & Reasoning Models

| Model ID | Provider | Description |
| :--- | :--- | :--- |
| `gpt-oss-20b` | OpenAI OSS | 20B parameter open-source GPT variant |
| `gpt-oss:20b` | OpenAI OSS | Alternative syntax for gpt-oss-20b |
| `mistral-small-3.1-24b-instruct-2503` | Mistral | 24B instruction-tuned model |
| `meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo` | Meta | Llama 3.1 8B optimized for speed |
| `deepseek-v3.1:671b-terminus` | DeepSeek | 671B MoE model, excellent for coding |
| `gemini-2.5-flash-lite` | Google | Ultra-fast reasoning model |
| `GLM-4.6V-Flash` | Zhipu | Fast Chinese/English bilingual |
| `bidara` | Bidara | Biomimicry design assistant |

### Code Models

| Model ID | Provider | Description |
| :--- | :--- | :--- |
| `codestral-2405` | Mistral | Code generation (May 2024 release) |
| `codestral-2501` | Mistral | Code generation (Jan 2025 release) |
| `ministral-8b-2512` | Mistral | Compact 8B model for fast responses |

---

## Image & Audio Models

| Model ID | Provider | Tier | Description |
| :--- | :--- | :--- | :--- |
| `flux` | Flux | Pro | High-quality image generation |
| `whisper-1` | OpenAI | Pro | Speech-to-text transcription |

---

## Choosing a Model

<Tip>
  **Not sure which model to use?** Start with `default` — it automatically routes to the best model for your use case.
</Tip>

| Use Case | Recommended Model |
| :--- | :--- |
| General chat | `default` or `gpt-oss-20b` |
| Complex coding | `deepseek-v3.1:671b-terminus` or `codestral-2501` |
| Fast responses | `gemini-2.5-flash-lite` or `ministral-8b-2512` |
| Chinese/English | `GLM-4.6V-Flash` |

---

<Card title="Upgrade to Pro" icon="crown" href="https://llm.kiwi/pricing" horizontal>
  Unlock all Pro models and higher rate limits.
</Card>

